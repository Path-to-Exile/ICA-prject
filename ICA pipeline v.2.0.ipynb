{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "from coroica import CoroICA, UwedgeICA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band-Pass filter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-Pass filter options\n",
    "fs = 250 # sampling frequency\n",
    "order = 3\n",
    "nyq = 0.5 * fs\n",
    "# BETA\n",
    "lowcut = 13\n",
    "highcut = 30\n",
    "low = lowcut / nyq\n",
    "high = highcut / nyq\n",
    "b_beta, a_beta = butter(order, [low, high], btype='band')\n",
    "\n",
    "#ALPHA\n",
    "\n",
    "lowcut_alpha = 8\n",
    "highcut_alpha = 13\n",
    "low_alpha = lowcut_alpha / nyq\n",
    "high_alpha = highcut_alpha / nyq\n",
    "b_alpha, a_alpha = butter(order, [low_alpha, high_alpha], btype='band')\n",
    "# ALPHA + BETA\n",
    "lowcut = 8\n",
    "highcut = 30\n",
    "low = lowcut / nyq\n",
    "high = highcut / nyq\n",
    "b_alp_be, a_alp_be = butter(order, [low, high], btype='band')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAR Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from Weichwald repository.\n",
    "# returns basis of A's null space\n",
    "def null(A, eps=1e-15):\n",
    "    # svd\n",
    "    u, s, v = np.linalg.svd(A)\n",
    "    # dimension of null space\n",
    "    padding = max(0, np.shape(A)[1] - np.shape(s)[0])\n",
    "    # select columns/rows corresponding to v\n",
    "    null_mask = np.concatenate(((s <= eps),\n",
    "                                np.ones((padding,), dtype=bool)), axis=0)\n",
    "    null_space = np.compress(null_mask, v, axis=0)\n",
    "    return null_space\n",
    "\n",
    "\n",
    "def carcomplement(samples):\n",
    "    d = samples.shape[0]\n",
    "    carcomp = null(np.ones((1, d)))\n",
    "    return carcomp.dot(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for loading data and converting to correct form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data functions\n",
    "NO_channels = 22\n",
    "def extract_data(subject,training,PATH):\n",
    "    # Arguments:\n",
    "    # Subject, number 1 to 9\n",
    "    # Training or evaluation, boolean value\n",
    "    # Absolute path\n",
    "    # Return: Tuple where\n",
    "    # data_rutern: numpy matrix, size = NO_valid_trial x 22 x window_length\n",
    "    # class_return: numpy matrix, size = NO_valid_trial  \n",
    "    \n",
    "    NO_channels = 22\n",
    "    NO_tests = 6*48\n",
    "    Window_Length = 3*250\n",
    "    \n",
    "    data_return = np.zeros((NO_tests,NO_channels,Window_Length))\n",
    "    class_return = np.zeros(NO_tests)\n",
    "    #subject_return = np.zeros(NO_tests)\n",
    "    \n",
    "    NO_valid_trial = 0\n",
    "    if training:\n",
    "        a = sio.loadmat(PATH+'A0'+str(subject)+'T.mat')\n",
    "    else:\n",
    "        a = sio.loadmat(PATH+'A0'+str(subject)+'E.mat')\n",
    "        \n",
    "    a_data = a['data']\n",
    "    for i in range(0,a_data.size):\n",
    "        a_data1     = a_data[0,i]\n",
    "        a_data2     = [a_data1[0,0]]\n",
    "        a_data3     = a_data2[0]\n",
    "        a_X         = a_data3[0]\n",
    "        a_trial     = a_data3[1]\n",
    "        a_y         = a_data3[2]\n",
    "        a_artifacts = a_data3[5]\n",
    "        for trial in range(0,a_trial.size):\n",
    "            if(a_artifacts[trial]==0):  \n",
    "                data_return[NO_valid_trial,:,:] = np.transpose(a_X[int(a_trial[trial])+750:(int(a_trial[trial])+Window_Length)+750,:22])\n",
    "                class_return[NO_valid_trial] = int(a_y[trial])\n",
    "                #subject_return[NO_valid_trial]= subject\n",
    "                NO_valid_trial += 1\n",
    "    return data_return[0:NO_valid_trial,:,:], class_return[0:NO_valid_trial]\n",
    "path = \"/Users/Svesketerning/Google-Drev/Project in Statistics/data/\"\n",
    "\n",
    "def append_pers_data(pers_list):\n",
    "    \n",
    "    eeg_data = list(extract_data(pers_list[0],True,path))\n",
    "    eeg_temp_init = list(extract_data(pers_list[0],False,path)) # Doing it like this because I am dumb\n",
    "    eeg_data[0] = np.append(eeg_data[0],eeg_temp_init[0], axis = 0)\n",
    "    eeg_data[1] = np.append(eeg_data[1],eeg_temp_init[1], axis = 0)\n",
    "    for i in pers_list[1:]:\n",
    "        eeg_temp = list(extract_data(i,True,path))\n",
    "        eeg_data[0] = np.append(eeg_data[0],eeg_temp[0], axis = 0)\n",
    "        eeg_data[1] = np.append(eeg_data[1],eeg_temp[1], axis = 0)\n",
    "        eeg_temp2 = list(extract_data(i,False,path))\n",
    "        eeg_data[0] = np.append(eeg_data[0],eeg_temp2[0], axis = 0)\n",
    "        eeg_data[1] = np.append(eeg_data[1],eeg_temp2[1], axis = 0)\n",
    "    return eeg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making subsets to pass into pipeline and defining CAR function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making subsets to pass into pipeline\n",
    "def subset_make(no_test):\n",
    "    subset_choices = []\n",
    "    for i in list(range(1,9)): # People to test on 1-9 range(1,9)\n",
    "        prior_choices = []\n",
    "        for ii in range(no_test): # Number of tests\n",
    "            choice_persons = list(np.random.choice(range(1,10),i,replace=False)) #Training subset\n",
    "            #while choice_persons in prior_choices:\n",
    "            #    choice_persons = list(np.random.choice(range(1,10),i,replace=False))\n",
    "            prior_choices.append(choice_persons)\n",
    "        subset_choices.append(prior_choices)\n",
    "    return subset_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAR(X,Y,car):\n",
    "    if car:\n",
    "        X,Y = carcomplement(X),carcomplement(Y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amateur built pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICA_pipeline(no_people,no_test,ICA_list,classifier,car,alpha):\n",
    "    # no_people; List of number of people to test on, e.g. [3,5,8]\n",
    "    # no_test; Number of test for each number of people, max 8 \n",
    "    # ICA_list; List of ICA method to test\n",
    "    #classifier; which classifier to use\n",
    "    #CAR; Should the function perform CAR, True or False\n",
    "    #alpha; Should you use both a alpha and beta filter or just beta filter, True or False\n",
    "    subset_choices = subset_make(no_test)\n",
    "    accuracy = []\n",
    "    for i in tqdm(no_people): \n",
    "        for ii in tqdm(range(no_test)):\n",
    "            current_subset = (subset_choices[i-1])[ii] # Subsetting \n",
    "            X1,Y1 = append_pers_data(current_subset),append_pers_data(list(set(range(1,10))-set(current_subset)))\n",
    "            X,Y = np.concatenate([X1[0][c] for c in range(len(X1[0]))],axis = 1),np.concatenate([Y1[0][c] for c in range(len(Y1[0]))],axis = 1)\n",
    "            X,Y = CAR(X,Y,car)\n",
    "            X,Y = X.transpose(),Y.transpose()\n",
    "            # ICA\n",
    "            for method in ICA_list:\n",
    "                transformer = method\n",
    "                X_transform = (transformer.fit_transform(X)).transpose()\n",
    "                if alpha:\n",
    "                    X_transform_alpha = lfilter(b_alpha,a_alpha,X_transform)\n",
    "                    X_transform_alpha = X_transform_alpha.reshape((NO_channels-1*car, len(X1[0]), 750))\n",
    "                    # Features if alpha\n",
    "                    Features_alpha = np.log(np.var(X_transform_alpha, axis = 2))\n",
    "                    Features_alpha = Features_alpha.transpose()\n",
    "                X_transform = lfilter(b_beta,a_beta,X_transform) #Insert a,b _alp_bet + alpha=False if one wants wide band range                              \n",
    "                X_transform = X_transform.reshape((NO_channels-1*car, len(X1[0]), 750))\n",
    "                \n",
    "                # Features\n",
    "                Features = np.log(np.var(X_transform, axis = 2))\n",
    "                Features = Features.transpose()\n",
    "                \n",
    "                if alpha:\n",
    "                    Features = np.column_stack((Features,Features_alpha))\n",
    "                # Classifier\n",
    "                clf = classifier\n",
    "                clf = clf.fit(Features, X1[1])\n",
    "                \n",
    "                # Evaluation \n",
    "                Y_transform = (transformer.transform(Y)).transpose()\n",
    "                \n",
    "                if alpha:\n",
    "                    Y_transform_alpha = lfilter(b_alpha,a_alpha,Y_transform)\n",
    "                    Y_transform_alpha = Y_transform_alpha.reshape((NO_channels-1*car, len(Y1[0]), 750))\n",
    "                    # Features is alpha\n",
    "                    Features_Y_alpha = np.log(np.var(Y_transform_alpha, axis = 2))\n",
    "                    Features_Y_alpha = Features_Y_alpha.transpose()\n",
    "                        \n",
    "                Y_transform = lfilter(b_beta,a_beta,Y_transform)\n",
    "                Y_transform = Y_transform.reshape((NO_channels-1*car, len(Y1[0]), 750))\n",
    "                Features_Y = np.log(np.var(Y_transform, axis = 2))\n",
    "                Features_Y = Features_Y.transpose()\n",
    "                \n",
    "                if alpha:\n",
    "                    Features_Y = np.column_stack((Features_Y,Features_Y_alpha))     \n",
    "                accuracy.append(np.mean(clf.predict(Features_Y)==Y1[1]))\n",
    "    # Accuracy list order: method 1 * subset 1,method 2 * subset 1... method n * subset1, method 1 * subset 2...\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Parameter choices, ICA's and Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 10**(-12)\n",
    "n_iter_max = 10000 \n",
    "n_components = NO_channels-1 # Number of components to extract, minus 1 because of CAR\n",
    "partition_size = 3000 # Same as Pfister, Weichwald et al. 2019.\n",
    "partition_sizes = 10**10 # Greater than number of observations >30*10^6.\n",
    "group_size = 520*750 # Approximately one for each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/ SOBI\n",
    "ica_method_list = [FastICA(tol=eps,max_iter=n_iter_max), # fastICA\n",
    "                CoroICA(#coroICA (var)\n",
    "                    partitionsize = partition_size,\n",
    "                    groupsize = int(500*750), #group_size\n",
    "                    tol=eps,\n",
    "                    max_iter=n_iter_max,\n",
    "                    condition_threshold=1000,\n",
    "                    pairing='neighbouring',\n",
    "                    instantcov=True,\n",
    "                    timelags=None),\n",
    "                UwedgeICA(#choiICA (var)\n",
    "                    partitionsize = partition_size,\n",
    "                    tol=eps,\n",
    "                    max_iter=n_iter_max,\n",
    "                    condition_threshold=1000,\n",
    "                    instantcov=True,\n",
    "                    timelags=None),\n",
    "                UwedgeICA(partitionsize=partition_sizes, #SOBI\n",
    "                    tol=eps,\n",
    "                    max_iter=n_iter_max,\n",
    "                    condition_threshold=1000,\n",
    "                    instantcov=False, # False in SOBI\n",
    "                    timelags=list(range(1, 14)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/o SOBI\n",
    "ica_method_list2 = [FastICA(tol=eps,max_iter=n_iter_max), # fastICA\n",
    "                CoroICA(#coroICA (var)\n",
    "                    partitionsize = partition_size,\n",
    "                    groupsize = int(500*750), #group_size\n",
    "                    tol=eps,\n",
    "                    max_iter=n_iter_max,\n",
    "                    condition_threshold=1000,\n",
    "                    pairing='neighbouring',\n",
    "                    instantcov=True,\n",
    "                    timelags=None),\n",
    "                UwedgeICA(#choiICA (var)\n",
    "                    partitionsize = partition_size,\n",
    "                    tol=eps,\n",
    "                    max_iter=n_iter_max,\n",
    "                    condition_threshold=1000,\n",
    "                    instantcov=True,\n",
    "                    timelags=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "quad_clf = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.1,\n",
    "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
    "rf_clf = RandomForestClassifier(max_depth=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "############### Pipeline study ###############\n",
    "##############################################\n",
    "# Quad_clf, CAR, alpha+beta\n",
    "accuracy_list1 = ICA_pipeline([4],20,ica_method_list,quad_clf,True,True)\n",
    "\n",
    "# Quad_clf, CAR, beta\n",
    "accuracy_list2 = ICA_pipeline([4],20,ica_method_list,quad_clf,True,False)\n",
    "\n",
    "# Quad_clf, no-CAR, alpha+beta\n",
    "accuracy_list3 = ICA_pipeline([4],20,ica_method_list,quad_clf,False,False)\n",
    "\n",
    "# Quad_clf, no-CAR, beta\n",
    "accuracy_list4 = ICA_pipeline([4],20,ica_method_list,quad_clf,False,False)\n",
    "\n",
    "# rf_clf, CAR, alpha+beta\n",
    "accuracy_list5 = ICA_pipeline([4],20,ica_method_list,rf_clf,True,True)\n",
    "\n",
    "#rf_clf, CAR, beta\n",
    "accuracy_list6 = ICA_pipeline([4],20,ica_method_list,rf_clf,True,False)\n",
    "\n",
    "# rf_clf, no-CAR, alpha+beta\n",
    "accuracy_list7 = ICA_pipeline([4],20,ica_method_list,rf_clf,False,True)\n",
    "\n",
    "# rf_clf, no-CAR, beta\n",
    "accuracy_list8 = ICA_pipeline([4],20,ica_method_list,rf_clf,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected = [] # Collect data\n",
    "collected.extend(accuracy_list1)\n",
    "collected.extend(accuracy_list2)\n",
    "collected.extend(accuracy_list3)\n",
    "collected.extend(accuracy_list4)\n",
    "collected.extend(accuracy_list5)\n",
    "collected.extend(accuracy_list6)\n",
    "collected.extend(accuracy_list7)\n",
    "collected.extend(accuracy_list8)\n",
    "\n",
    "## Function to make accuracy score to dataframe (Note the order the data is stored in in pipeline function)\n",
    "def main1(accuracy_list):\n",
    "    df = pd.DataFrame(columns = ['ICA_method','Pipeline','Accuracy'])\n",
    "    df = df.assign(Accuracy = accuracy_list)\n",
    "    df = df.assign(Train_Size = np.repeat(4,20*4*8))\n",
    "    df = df.assign(Pipeline = np.repeat(['QDA & CAR & Alpha+Beta',\n",
    "                                        'QDA & CAR & Beta',\n",
    "                                        'QDA & no-CAR & Alpha+Beta',\n",
    "                                        'QDA & no-CAR & Beta', \n",
    "                                        'RF & CAR & Alpha+Beta',\n",
    "                                        'RF & CAR & Beta',\n",
    "                                        'RF & no-CAR & Alpha+Beta',\n",
    "                                        'RF & no-CAR & Beta'],20*4))\n",
    "    df = df.assign(ICA_method = ['fastICA','coroICA (var)','choiICA (var)', 'SOBI']*20*8)\n",
    "    return df\n",
    "df = main1(collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(30,20)})\n",
    "sns.set(font_scale = 2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 1, sharex=False,sharey = True)\n",
    "sns.despine(left=True)\n",
    "\n",
    "bx = sns.boxplot(x=\"Pipeline\", y=\"Accuracy\", hue=\"ICA_method\", \n",
    "                    palette=\"Blues_d\",saturation=0.65, \n",
    "                    fliersize = 0, whis = 1.27,\n",
    "                     data=df[:320], ax=axes[0])\n",
    "cx = sns.boxplot(x=\"Pipeline\", y=\"Accuracy\", hue=\"ICA_method\", \n",
    "                    palette=\"Blues_d\",saturation=0.65, \n",
    "                    fliersize = 0, whis = 1.27,\n",
    "                     data=df[320:], ax=axes[1])\n",
    "bx.axhline(0.25, xmin = -1, xmax=8, color = 'r', linewidth = 4, linestyle = 'dashed')\n",
    "cx.axhline(0.25, xmin = -1, xmax=8, color = 'r', linewidth = 4, linestyle = 'dashed')\n",
    "plt.legend(fontsize='medium', loc='upper right')\n",
    "cx.legend().remove()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bx.get_figure()\n",
    "fig.savefig('pipeline-figure.pdf', format='pdf', dpi=1200)\n",
    "df.to_csv('pipeline-study.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to wide filter (should change pipeline function before running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list9 = ICA_pipeline([4],20,ica_method_list2,quad_clf,True,False)\n",
    "accuracy_list10 = ICA_pipeline([4],20,ica_method_list2,quad_clf,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected2 = []\n",
    "collected2.extend(accuracy_list9)\n",
    "collected2.extend(accuracy_list10)\n",
    "def main2(accuracy_list):\n",
    "    df = pd.DataFrame(columns = ['ICA_method','Pipeline','Accuracy'])\n",
    "    df = df.assign(Accuracy = accuracy_list)\n",
    "    df = df.assign(Train_Size = np.repeat(4,20*3*2))\n",
    "    df = df.assign(Pipeline = np.repeat(['QDA & CAR & alpha/beta',\n",
    "                                        'QDA & no-CAR & alpha/beta'],20*3*8))\n",
    "    df = df.assign(ICA_method = ['fastICA','coroICA (var)','choiICA (var)']*20*2)\n",
    "    return df\n",
    "df2 = main2(collected2)\n",
    "df3 = pd.DataFrame.append(df,df2) # Collect the big df with the alpha/beta for comparison\n",
    "##### delete unnecessary data (doing like this because I could not figure out a better way) #####\n",
    "df3.drop(df.loc[df['ICA_method'] == 'SOBI'].index, inplace=True)\n",
    "df3.drop(df.loc[df['Pipeline'] == 'RF & CAR & Alpha+Beta'].index, inplace=True)\n",
    "df3.drop(df.loc[df['Pipeline'] == 'RF & CAR & Beta'].index, inplace=True)\n",
    "df3.drop(df.loc[df['Pipeline'] == 'RF & no-CAR & Alpha+Beta'].index, inplace=True)\n",
    "df3.drop(df.loc[df['Pipeline'] == 'RF & no-CAR & Beta'].index, inplace=True)\n",
    "df3.drop(df.loc[df['Pipeline'] == 'QDA & CAR & Beta'].index, inplace=True)\n",
    "df3.drop(df.loc[df['Pipeline'] == 'QDA & no-CAR & Beta'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(30,10)})\n",
    "sns.set(font_scale = 2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1)\n",
    "bx = sns.boxplot(x=\"Pipeline\", y=\"Accuracy\", hue=\"ICA_method\", \n",
    "                    palette=\"Blues_d\",saturation=0.65, \n",
    "                    fliersize = 0, whis = 1.27,\n",
    "                     data=df3)\n",
    "bx.axhline(0.25, xmin = -1, xmax=5, color = 'r', linewidth = 4, linestyle = 'dashed')\n",
    "plt.legend(fontsize='medium', loc='upper right')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bx.get_figure()\n",
    "fig.savefig('bands-comparison.pdf', format='pdf', dpi=1200)\n",
    "df3.to_csv('bands-comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different size subset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list11 = ICA_pipeline([1,2,3,4,5,6,7,8],20,ica_method_list2,quad_clf,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main3(accuracy_list):\n",
    "    df = pd.DataFrame(columns = ['ICA_method','Pipeline','Accuracy'])\n",
    "    df = df.assign(Accuracy = accuracy_list)\n",
    "    df = df.assign(Train_Size = np.repeat([1,2,3,4,5,6,7,8],20*3))\n",
    "    df = df.assign(Pipeline = np.repeat(['QDA & CAR & Beta'],20*8*3))\n",
    "    df = df.assign(ICA_method = ['fastICA','coroICA (var)','choiICA (var)']*20*8)\n",
    "    return df\n",
    "df4 = main3(accuracy_list11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot creation (lineplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(25,10)})\n",
    "sns.set(font_scale = 2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1)\n",
    "bx = sns.lineplot(x=\"Train_Size\", y=\"Accuracy\", hue=\"ICA_method\", \n",
    "                    palette= \"colorblind\",\n",
    "                     data=df4)\n",
    "bx.axhline(0.25, xmin = -1, xmax= 1, color = 'r', linewidth = 2, linestyle = 'dashed')\n",
    "plt.legend(fontsize='small', loc='upper left')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bx.get_figure()\n",
    "fig.savefig('big-analysis.pdf', format='pdf', dpi=1200)\n",
    "df4.to_csv('big-analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
